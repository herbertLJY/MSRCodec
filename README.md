<div align="center">
    <h1>
    MSR-Codec
    </h1>
    <p>
    Official PyTorch code for inference of <br>
    <b><em>MSR-Codec: A Low-Bitrate Multi-Stream Residual Codec for High-Fidelity Speech Generation with Information Disentanglement</em></b>
    </p>
    <p>
      Jingyu Li^1, Guangyan Zhang^1, Zhen Ye^2, Yiwen Guo^3<br>
      1^LIGHTSPEED, Hong Kong SAR<br>
      2^The Hong Kong University of Science and Technology, Hong Kong SAR<br>
      3^Independent Researcher, Corresponding Author<br>
    </p>
</div>

<!-- ## MSR-Codec ðŸ”¥ -->

### Overview

Audio codecs are a critical component of modern speech generation systems. This paper introduces a low-bitrate, multi-scale residual codec that encodes speech into four distinct streams: semantic, timbre, prosody, and residual. This architecture achieves high-fidelity speech reconstruction at competitive low bitrates while demonstrating an inherent ability for information disentanglement. We construct a two-stage language model for text-to-speech (TTS) synthesis using this codec, which, despite its lightweight design and minimal data requirements, achieves a state-of-the-art Word Error Rate (WER) and superior speaker similarity compared to several larger models. Furthermore, the codecâ€™s design proves highly effective for voice conversion, enabling independent manipulation of speaker timbre and prosody.

Our paper on this project has been published! You can read it here: [MRS-Codec](https://arxiv.org/pdf/2509.13068).

### Key Words

- **Audio Codec**
- **Speech Generation**
- **Low-bitrate**
- **Information Disentanglement**



## Installation
**Clone and Install**

  Here are instructions for installing on Linux. 


- Clone the repo
``` sh
git https://github.com/herbertLJY/MSRCodec.git
cd MSRCodec
```

- Install Conda: please see https://docs.conda.io/en/latest/miniconda.html
- Create Conda env:

``` sh
conda create -n msrcodec -y python=3.10
conda activate msrcodec
```
- Please install the textless first, following https://github.com/facebookresearch/textlesslib/tree/main

- Or 
``` sh
git clone https://github.com/facebookresearch/textlesslib.git
git clone https://github.com/facebookresearch/fairseq.git
export PYTHONPATH=textlesslib/:fairseq/:$PYTHONPATH
```
- Install requried libraries:
``` sh
pip install -r requirements.txt
```

## **Basic Usage**

You can simply run the demo with the following commands:
``` sh
bash infer.sh
```

Alternatively, you can modify the script to generate your speechesï¼š

``` sh
python ignore inference.py \
    --prompt_wav assets/src/121_127105_000009_000000.wav \
    --prompt_text "We say, of course, somebody exclaimed, that they give two turns!" \
    --gen_text "How are you? This is lightspeed studio from tencent." \
    --output_dir out_dir
```

## **Demos**

Here are some demos generated by MSR-Codec using zero-shot voice cloning. For more demos, visit our [demo page](https://herbertljy.github.io/MSRCodec/).
